# Explaining and Harnessing Adversarial Examples

## 一、概要
### 这篇文章是对抗样本领域目前的一种主流解释，一作也是大名鼎鼎的Goodfellow。作者将对抗样本（Adversarial Examples，下文简称AE）的成因归结于神经网络（Neural Network, 下文简称NN）的线性，而非之前所认为的NN的非线性和过拟合。同时基于这一点提供了一种AE的快速生成法（Fast Gradient Sign Method, 下文简称FGSM），并对AE的跨训练集和模型的普适性做了解释。而且还提供了一种AE训练的方法来降低模型在测试的误差。

## 二、简介
### 1、AE对NN的盲点准确命中
### 2、对高维空间数据/模型不正确的线性拟合是AE产生的主因，由此产生FGSM
### 3、传统正则化方法对优化模型抗AE性能基本无效，但换模型（如RBF）则有效
### 4、易训练 VS 抗AE，目前两者需要权衡

## 三、相关工作
### （Goodfellow的无情嘲讽……）

## 四、AE的线性解释
### 根据文中数学分析可知，当模型涉及的数据维度相当高时，即使微小的扰动也会对模型本身造成巨大的影响，作者认为这就是AE的主因。

## 五、对非线性模型的线性扰动
