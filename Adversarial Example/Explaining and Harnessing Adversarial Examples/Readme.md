# Explaining and Harnessing Adversarial Examples

## 一、概要
### 这篇文章是对抗样本领域目前的一种主流解释，一作也是大名鼎鼎的Goodfellow。作者将对抗样本（Adversarial Examples，下文简称AE）的成因归结于神经网络（Neural Network, 下文简称NN）的线性，而非之前所认为的NN的非线性和过拟合。同时基于这一点提供了一种AE的快速生成法（Fast Gradient Sign Method, 下文简称FGSM），并对AE的跨训练集和模型的普适性做了解释。而且还提供了一种AE训练的方法来降低模型在测试的误差。

## 二、简介
### 1、AE对NN的盲点准确命中
### 2、对高维空间数据/模型不正确的线性拟合是AE产生的主因，由此产生FGSM
### 3、传统正则化方法对优化模型抗AE性能基本无效，但换模型（如RBF）则有效
### 4、易训练 VS 抗AE，目前两者需要权衡

## 三、相关工作
### （Goodfellow的无情嘲讽……）

## 四、AE的线性解释
### 根据文中数学分析可知，当模型涉及的数据维度相当高时，即使微小的扰动也会对模型本身造成巨大的影响，作者认为这就是AE的主因。

## 五、对非线性模型的线性扰动
### 这一节主要就是基于以上假设提出了FGSM，用来训练AE，而且获得了很高的成功率，因此说明了模型的线性是AE产生的原因之一。

## 六、AE辅助训练 VS 权重衰减
### 作者以传统的Logistic回归作为例子，比较了AE辅助训练和权重衰减的结果。发现在欠拟合条件下，AE辅助训练只会让结果更差。(当然L1范数优化也好不到哪儿去)
### 在多分类任务中，L1范数优化在独立扰动下众口难调，结果很不理想(更小的L1或许可行)；由上面推出的公式可以看出，更大L1的加入只会使得对AE扰动更加严重。

## 七、DNN的AE辅助训练
### DNN可以产生抗扰动模型，因为理论上只要神经网络足够大，它可以近似任意函数。但是在传统监督学习的过程中，并没有融入AE辅助训练，而AE辅助训练有利于DNN的正则化。
### 一个很难实现的构想：用L-BFGS方法生成AE来辅助训练。
### 可以用类似于FGSM的方法进行AE生成，而且确实可以改进模型在测试集的准确率。
### 但是为啥错误率没到0%？？？两个原因，一个是模型不够大；还有一个是两个模型早停的时间不同，往往在测试集上练的差不多了，在AE上仍未训练好，因此我们在AE辅助训练中同样设置早停，可以稍微提高点性能。
### 经过AE辅助训练的模型对AE有一定的抗性，不过不完全。而且没形成抗性的那部分结果对自己所做的错误判断依旧是信心满满……
### AE可以看作是一类启发式学习(是啊，真·举一反三)
### AE中起重要作用的，主要是扰动更大的噪声；那些0均值和0协方差的效果其实很差，所以一般噪声(高斯白噪声之类的)几乎没啥用……(其实Szegedy也做了实验，果然大佬所见略同)
