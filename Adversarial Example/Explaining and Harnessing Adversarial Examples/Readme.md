# Explaining and Harnessing Adversarial Examples

## 一、概要
### 这篇文章是对抗样本领域目前的一种主流解释，一作也是大名鼎鼎的Goodfellow。作者将对抗样本（Adversarial Examples，下文简称AE）的成因归结于神经网络（Neural Network, 下文简称NN）的线性，而非之前所认为的NN的非线性和过拟合。同时基于这一点提供了一种AE的快速生成法（Fast Gradient Sign Method, 下文简称FGSM），并对AE的跨训练集和模型的普适性做了解释。而且还提供了一种AE训练的方法来降低模型在测试的误差。

## 二、简介
### 1、AE对NN的盲点准确命中
### 2、对高维空间数据/模型不正确的线性拟合是AE产生的主因，由此产生FGSM
### 3、传统正则化方法对优化模型抗AE性能基本无效，但换模型（如RBF）则有效
### 4、易训练 VS 抗AE，目前两者需要权衡

## 三、相关工作
### （Goodfellow的无情嘲讽……）

## 四、AE的线性解释
### 根据文中数学分析可知，当模型涉及的数据维度相当高时，即使微小的扰动也会对模型本身造成巨大的影响，作者认为这就是AE的主因。

## 五、对非线性模型的线性扰动
### 这一节主要就是基于以上假设提出了FGSM，用来训练AE，而且获得了很高的成功率，因此说明了模型的线性是AE产生的原因之一。

## 六、AE辅助训练 VS 权重衰减
### 作者以传统的Logistic回归作为例子，比较了AE辅助训练和权重衰减的结果。发现在欠拟合条件下，AE辅助训练只会让结果更差。(当然L1范数优化也好不到哪儿去)
### 在多分类任务中，L1范数优化在独立扰动下众口难调，结果很不理想(更小的L1或许可行)；由上面推出的公式可以看出，更大L1的加入只会使得对AE扰动更加严重。

## 七、DNN的AE辅助训练
### DNN可以产生抗扰动模型，因为理论上只要神经网络足够大，它可以近似任意函数。但是在传统监督学习的过程中，并没有融入AE辅助训练，而AE辅助训练有利于DNN的正则化。
### 一个很难实现的构想：用L-BFGS方法生成AE来辅助训练。
### 可以用类似于FGSM的方法进行AE生成，而且确实可以改进模型在测试集的准确率。
### 但是为啥错误率没到0%？？？两个原因，一个是模型不够大；还有一个是两个模型早停的时间不同，往往在测试集上练的差不多了，在AE上仍未训练好，因此我们在AE辅助训练中同样设置早停，可以稍微提高点性能。
### 经过AE辅助训练的模型对AE有一定的抗性，不过不完全。而且没形成抗性的那部分结果对自己所做的错误判断依旧是信心满满……
### AE可以看作是一类启发式学习(是啊，真·举一反三)
### AE中起重要作用的，主要是扰动更大的噪声；那些0均值和0协方差的效果其实很差，所以一般噪声(高斯白噪声之类的)几乎没啥用……(其实Szegedy也做了实验，果然大佬所见略同)

## 十、两种和实验结果相悖的假说
### 1、生成式训练模型能够在AE辅助训练下习得对AE的抗性——结果并没有。
### 2、AE不过是单个模型的奇点，所以平均多个模型的值就能够抹平AE——团结没有力量。

## 十一、总结和讨论
### 1、AE是高维空间中向量内积线性化过度的结果
### 2、AE在各模型上普适性可以解释为模型从训练集中学得的权重向量相似
### 3、AE在输入空间中稀疏且稠密——就像实数域中的有理数集那样
### 4、介绍了FGSM
### 5、AE辅助训练是一种较强的正则化手段——比drop out还强
### 6、无法用L1范数和噪声简单再现AE
### 7、易优化 和 抗AE 是一组矛盾
### 8、抗AE模型训练需要模型本身具有额外的容量（更为复杂的hidden layer）——普通线性模型没有
### 9、RBF模型对AE有一定程度的免疫性
### 10、生成式学习对AE防御无效
### 11、集成学习对AE防御无效

## 十二、附录——冗余样本(Rubbish Class Examples，下文简称RE)
### RE是样本集中无法分类成任何一个类别的样本，换而言之，分类器对其输出的概率分布是近似均匀的(信息熵极高)，一般的处理方法就是在输出层多加一个“无类别”。
### 一般来说，NN对远离训练集的RE识别率低，而对训练集距离近的RE识别率高。
### RB误识别到特定类别的难度不一， 也可用和AE类似的生成方式，但RE辅助训练对模型提升无效。
