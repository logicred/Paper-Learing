# The Limitations of Deep Learning in Adversarial Settings

## 一、概述

### 这篇文章是EuroS&P2016的文章，提出了对于NN(Neural Network)进行对抗样本生成的具体分类，介绍了一种生成AE(Adversarial Example)的方法，并分析了对分类器各个分类攻击成功的难易程度，最后讨论了对AE的防御办法。

## 二、介绍

### 主要就是总结了一下前人的工作，一般都是采用梯度来进行AE的生成，而本文重点是：
### 1、构建了对攻击难易程度和普适程度的二维空间，用来衡量AE对抗效果的强弱。
### 2、利用前向微分而非梯度进行AE生成，构建AE特征图来解释AE边界。
### 3、分析AE特点，探讨常用AE的防御方法。

## 三、对于DL(Deep Learning)攻击模型的分类
### 主要分为两个维度：攻击目的&攻击所需要的信息
### 1、攻击目的：攻击强度由低到高分为
### (1)降低分类置信度
### (2)误分类
### (3)指定类别的误分类
### (4)对于任意输入，都能实现指定类别的误分类

### 2、攻击所需要的信息：信息量从大到小分为
### (1)已知训练集及网络结构
### (2)仅知网络结构
### (3)仅知训练集
### (4)仅可使用网络
### (5)仅知某些输入输出的对应关系

### 本文所述AE生成的属于高攻击强度、高信息量的方法(白箱攻击)

## 四、AE生成方法

