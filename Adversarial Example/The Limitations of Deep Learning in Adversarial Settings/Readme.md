# The Limitations of Deep Learning in Adversarial Settings

## 一、概述

### 这篇文章是EuroS&P2016的文章，提出了对于NN(Neural Network)进行对抗样本生成的具体分类，介绍了一种生成AE(Adversarial Example)的方法，并分析了对分类器各个分类攻击成功的难易程度，最后讨论了对AE的防御办法。

## 二、介绍

### 主要就是总结了一下前人的工作，一般都是采用梯度来进行AE的生成，而本文重点是：
### 1、构建了对攻击难易程度和普适程度的二维空间，用来衡量AE对抗效果的强弱。
### 2、利用前向微分而非梯度进行AE生成，构建AE特征图来解释AE边界。
### 3、分析AE特点，探讨常用AE的防御方法。

## 三、对于DL(Deep Learning)攻击模型的分类
### 主要分为两个维度：攻击目的&攻击所需要的信息
### 1、攻击目的：攻击强度由低到高分为
### (1)降低分类置信度
### (2)误分类
### (3)指定类别的误分类
### (4)对于任意输入，都能实现指定类别的误分类

### 2、攻击所需要的信息：信息量从大到小分为
### (1)已知训练集及网络结构
### (2)仅知网络结构
### (3)仅知训练集
### (4)仅可使用网络
### (5)仅知某些输入输出的对应关系

### 本文所述AE生成的属于高攻击强度、高信息量的方法(白箱攻击)

## 四、AE生成方法

### 1、简单NN例子——构建对于AND函数的攻击AE
###  一般都可以将AE的生成问题化归为优化问题，但是如何找寻合适的扰动是一个比较麻烦的问题。本文基于对网络函数F对输入特征的前向导数，寻求前向导数大的作为寻找优化的搜索方向。
### 可以发现，合适的小扰动可以引起分类的截然不同；前向导数往往可以指示如何缩小搜索范围；不是所有的类别都能成功扰动至另一类别。

### 2、适用到深层前馈网络——AE生成算法1.0
### 给定一些参数意义之后，就是一个简要的AE生成算法，后层的前向导数可以划归为一个递推问题，所以说计算方面还好。
### 算法中主要涉及到一个Saliency Map(SM)的计算，这个SM的计算公式已经成现在文中，直观上来看，它就是反应改动哪个输入特征对归到某一类有多大的帮助，由此我们可以获取到更好的扰动生成方法；同样的如果简单取反，就是我们应当对那些输入谨慎处理。(防御策略)
### 算法中人为参数只有扰动范围和每次扰动大小是人为确定的，将在之后章节详述。

## 五、实战

