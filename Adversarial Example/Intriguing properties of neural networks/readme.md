# Intriguing properties of neural networks

## 一、概要
### 这篇文章是对抗样本的开山之作，“对抗样本”的概念也是在这里提出的，文章主要讲了两件事：
### 1、发现语义信息并不依赖于单个神经元而存在，而很有可能是神经元的群体特征；
### 2、其次由于神经网络从输入到输出的不连续性，可以通过加上一些人眼不可察的扰动（对抗样本）来使神经网络做出错误的判断。

## 二、简介
### 1、单个神经元的激活函数Φ(x)不唯一对应某种特征——也就是说神经网络对图像特征的处理分散存在于各个神经元中。
### 2、存在一些对抗样本，也即可以通过加上一些人眼不可察的扰动（对抗样本）来使神经网络做出错误的判断。
### 3、对抗样本具有普适性——可以迁移到其它网络甚至线性分类器上。
### 4、由BP(误差逆传播)组建的DNN(深度学习网络)是有盲点的，本身映射具有不连续性。

## 三、框架
### 略(都是一些基本概念)。

## 四、神经单元的激活函数Φ(x)

### 传统的CV(计算机视觉)往往认为单个特征主要依赖某个神经元，因此提升网络的方法往往是更好地激活对应的神经元，然而文章认为并非如此。

### 在Figure1和Figure2中，分别激活对应不同曲直和位置特性的敏感的神经元，可以发现它们对于很多图像的感知是共享的。也就是说，给一个任意方向和任意曲直特性的图像，在各个神经元上都会或多或少产生特征信息，因此语义信息并不依赖于单个神经元而存在，而很有可能是神经元的群体特征。

## 五、神经网络中的盲点
### 对于神经网络而言，其输入到输出的映射一般都是非线性的。因此两个在标准距离度量下(像素意义上)相距甚远的样本，事实上可能共享着一个标签。
### 而一般来说，我们往往期待着这样的模型——邻域完备性：我们在训练样本附近加一个任意小的扰动，都能维持原分类的不变。换言之我们期待在分类边界处的映射是连续的(光滑的)。
### 然而不幸的是，很多DNN网络并不拥有如上特性(由于非线性)。在文中给出了一种优化方法来找出这样的扰动——对抗样本。
### 令人惊奇的是，这种扰动是具有普适性的，它或许代表着DNN映射中小概率的不连续部分，因此正常随机采样很难成功找到这样的扰动。然而一般的DNN都采用某种方法来处理图像，从而提升模型性能，而这种对图像的预处理恰恰是对抗的突破口。

## 六、数学描述
### 我们的任务实际上就是在给定目标标签L的情况下，计算出最小的扰动R使得某样本X被识别为L。为了方便处理，将X+R映射为[0,1]，并用罚函数权衡扰动R和LOSS函数。

## 七、实验结果
### 1、对于每个神经网络、各个样本均能找到对应的对抗样本。
### 2、若结构相近，即使超参数不同，对抗样本的普适性就很好。
### 3、即使训练集改变而神经网络相同，原对抗样本仍然适用。
### 由上可以看出，对抗样本并非overfit或者数据集选取不佳造成的，我们甚至可以通过不断生成对抗样本，给模型“接种”，使得其获得一定免疫性，而提升模型性能。而基于一些实验，文章发现对抗样本对深层网络对影响较之浅层网络更甚。

## 七补、具体实验
### 实验一(TABLE 1)：
### 1、普通线性分类器（不同loss权重）——受到对抗样本扰动
### 2、FC神经网络（不同网络结构）——依然受到对抗样本扰动
### 3、AE自动编码器——还是受到对抗样本扰动
### 实验二(TABLE 2)同训练集，不同神经网络的对抗样本普适性:
### 1、同结构扰动极大。
### 2、高斯噪声要达到对抗样本的扰动程度需要对原图像造成极大变动（对抗样本的微小性）。
### 3、AE对对抗样本有一定免疫能力，不过依旧有影响。
### 实验三(TABLE 3 ，4)不同训练集，同一/不同神经网络的对抗样本普适性：
### 1、确实具有普适性(根深蒂固)，尽管衰减的很快。
### 2、对抗样本微调(向扰动后结果线性逼近10%)，导致误判率急剧上升。

## 八、不稳定性的部分理论解释
### 文中认为不稳定性部分因为神经网络参数(DNN/CNN/...)设定时,生成的函数模型不满足K阶Lipschitz连续条件，使得存在一些间断点。因此对参数的正则化调整可能有助于避免该类问题。

## 九、总结
### 为何DNN做图像分类很好，但是对对抗样本稳健性差？——可能是对抗样本概率小，没学到。
### 实际上本文也对对抗样本生成原因&作用原理不甚明了。

