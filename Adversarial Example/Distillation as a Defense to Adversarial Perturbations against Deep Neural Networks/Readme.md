# Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks

## 一、概述：

### DNN(Deep Nerual Network)对AE(Adversarial Example)很脆弱，本文采用一种称为DD(Defensive Distillation)的方法来降低AE对DNN的影响，能将误判率从95%降到0.5%，同时能够将梯度降低至原来的1/10 ^ 30；而AE所需的攻击特征数大约要提升800%，攻击更为艰难。

## 二、简介：

### 由于其优秀的表现， DNN被广泛地应用在各行各业中。然而AE对DNN来说是很有效的一种攻击方法，并且防御方法有限，一般都是通过修改模型/针对部分AE进行防御。而蒸馏(Distillation)是将一个DNN训练所得信息来训练另一个DNN，从而起到压缩DNN规模和计算量，实现在微小系统上的智能计算。

### 在这篇文章中，DD能够降低DNN的梯度变化，从而抑制各种针对梯度进行AE生成的各种方法。可以认为，是针对输入对网络进行平滑。

### 本文贡献点：
### 1、阐述了DNN防御AE需要达成的几个条件；
### 2、蒸馏(Distillation)思想的应用；
### 3、能够平滑模型；
### 4、AE攻击成功率下降——能将误判率从95%降到0.5%；
### 5、AE攻击困难上升——同时能够将梯度降低至原来的1/10 ^ 30；而AE所需的攻击特征数大约要提升数倍，攻击更为艰难。

## 三、对抗DNN：

### 1、AE集上的DNN
### 本文只考虑监督学习下，且不考虑训练时受到攻击的情况。我们可以发现，AE能够通过对样本施加人眼无法观察的扰动而使得分类器误判。更进一步，我们甚至可以指定误判之后的类别。当然，这需要攻击者对此分类器有一定的了解，但是AE在不同分类器的普适性使得黑箱攻击亦成为可能。

### 2、AE攻击框架
### 一般分为两步：
### 类别敏感度测试——测试输入改变对分类类别的影响(FGSM、JSMA、KL)；
### 扰动筛选——在最小化扰动大小的情况下，进行扰动的选择(度量的选择是重点)。

### 3、神经网络蒸馏(Distillation)
### 蒸馏——用一个神经网络的训练输出，作为另外一个神经网络的软标签输入，这样可以相对于硬标签提供更多的信息熵，从而使得能够用更为浅层的神经网络完成相应的功能。
### 蒸馏的关键参数——温度T，当温度T增大时，使得软标签趋同，产生的互信息增大，但有可能使得标签本身无意义；反之软标签趋于分立，产生的互信息减小，但是标签本身更有价值。
### 本文中， 第一个DNN和第二个DNN温度T相同，训练时T > 1，测试时T = 1(无蒸馏)。

## 四、用蒸馏来防御DNN(DD的思想)

### 1、防御AE的扰动
### 一般来说，AE生成主要是通过梯度来进行的，这些梯度越大，导致AE的扰动就越容易生成，因此我们要做的就是平滑梯度，抑制AE生成。
### DNN稳健性包括两方面，一来它本身的准确率要高；二来它需要满足“近邻平滑”特性(微小的变动并不影响分类结果)。一般可以认为DNN稳健性为其各个样本处的近邻域大小平均。
### 防御DNN需要满足以下几个特点——对DNN本身框架影响尽量小&不降低分类准确率&不影响运行时间&平滑邻域。
### 作者称本文的DD恰好可以满足这几点

### 2、DD
### 用样本X和硬标签Y(X)训练DNN1，使得其输出为一个概率分布F(X)(过softmax层后)。再用样本X和软标签F(X)训练DNN2(DNN2和DNN1结构相同，温度T也相同)，通过增大了互信息，减小了梯度，来提升对抗AE的性能。
